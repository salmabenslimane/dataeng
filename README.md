ğŸ“‚ Overview 
API â†’ DuckDB â†’ Airflow â†’ Streamlit

Programming Language: Python
Data Sources: Mock API (Mockaroo)
Storage: DuckDB
Orchestration: Airflow (Airflow DAG runs your CLI tools (init-db.py, fetch-data.py) on a schedule â†’ updates DuckDB)


ğŸ“‚ DB Folder Structure 

init\db/
â”œâ”€â”€ raw_data.duckdb         â† The actual DuckDB database file
â”œâ”€â”€ init_schema.py          â† Script to define your schema (raw.orders, raw.users, etc.)
â”œâ”€â”€ fetch_and_insert.py     â† Script to fetch from API and insert into DuckDB
â””â”€â”€ config.json             â† Store API URLs, keys, etc.


ğŸ“‚ Iterations: 

Iteration 1: Create all the functional code 
Iteration 2: Turn following files into CLI tools (init-db.py and fetch-data.py)



| Mini-project (Mockaroo)            | Air France real use case                              |
| ---------------------------------- | ----------------------------------------------------- |

| Random new data every API call     | New flight bookings, cancellations, check-ins         |

| You fetch periodically via Airflow | Automated ETL pipeline fetching new events            |

| Insert into DuckDB                 | Insert into production warehouse (BigQuery/Snowflake) |

| Raw schema stays the same          | Raw tables always have same structure                 |



ğŸ”¹ Features : 

Booking_ID	
Booking_Date
Flight_ID	
Flight_Date
Passenger_ID	
Passenger_Name	
Email	
Gender  
Country_Code	
Ticket_Class	
Quantity	
Unit_Price	
Payment_Method	
Booking_Status	
Revenue

